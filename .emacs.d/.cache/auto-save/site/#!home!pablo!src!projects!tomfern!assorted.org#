* DUPLICATE?
* TODO Benchmarking with sysbench                         :sysbench:benchmarking:guides:
* TODO Sysbench for databases                   :mysql:pgsql:sysbench:guides:
:PROPERTIES:
:EXPORT_FILE_NAME: sysbench-p2
:END:

This is my second part of the sysbench guide, I'll cover here some basic benchmarks for databases. Feel free to check my first part where we test the system.

** Connecting to the DB

First things first, we'll a test database. We'll stick to the default "sbtest", connect to your database and create it:

    =create database sbtest;=

Now sysbench needs the connection parameters. The actual values depend on the target. Sysbench supports MySQL and postgreSQL.

For MySQL, MariaDB or Percona Server the command line options are:

#+BEGIN_SRC 
    --db-driver=mysql
    --mysql-host=
    --mysql-port=
    --mysql-user=
    --mysql-password=
#+END_SRC

For postgreSQL, we have:

#+BEGIN_SRC 
    --db-driver=pgsql
    --pgsql-host=
    --pgsql-port=
    --pgsql-user=
    --pgsql-password=
#+END_SRC

For brevity's sake, I will be /omitting these parameters/ in the examples below, but they are required so don't you forget them.

** The test table
   
Here we have the prototypical test table

#+BEGIN_SRC sql 
CREATE TABLE `sbtest1` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `k` int(11) NOT NULL DEFAULT 0,
  `c` char(120) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '',
  `pad` char(60) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '',
  PRIMARY KEY (`id`),
  KEY `k_1` (`k`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
#+END_SRC

That's it, 4 columns: 2 integer and 2 chars. Unfortunately we don't have so many built-in options to tweak the table as in other tools such as mysqlslap [link].
We do, however, have some control.

#+BEGIN_SRC 
--auto_inc[=on|off]              sets the id column as autoincrement/serial
--create_secondary[=on|off]      creates a secondary index on column k (on)
--mysql_storage_engine=[engine]  storage engine, only applies to MySQL (innodb)
#+END_SRC

The =id= column is populated either by the DB (with autoincrement/serial), or by sequential integers generated by sysbench, 
=k= is assigned a random number between 1 and whatever the table size is. The char columns are filled with random numbers, 
in groups of 11 digits separated by dashes, no index is created for either =c= or =pad=.

** Bulk insert

Bulk insert does concurrent multi-row inserts, we specify how many threads we want and each one inserts into its own table.
So the total number of tables is the same as the number of threads.

The default is 1 thread. But that is easily changed. Let's create 20 tables.

/(remember that the db connection parameters are omitted)/

#+caption: preparing tables for bulk_insert
#+BEGIN_SRC 
sysbench bulk_insert prepare --threads=20
#+END_SRC

Now lets insert 1M rows and see how long it takes. The rows distributed  over all the tables.

#+caption: bulk_insert test, 1M rows, 20 threads
#+BEGIN_SRC  
# Insert 1M rows total, concurrently on the 20 tables
sysbench bulk_insert run --threads=20 --events=1000000 --time=0

sysbench 1.0.15 (using system LuaJIT 2.0.5)

Running the test with following options:
Number of threads: 20
Initializing random number generator from current time


Initializing worker threads...

Threads started!

SQL statistics:
    queries performed:
        read:                            0
        write:                           43
        other:                           0
        total:                           43
    transactions:                        1000000 (144368.49 per sec.)
    queries:                             43     (6.21 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          6.9213s
    total number of events:              1000000

Latency (ms):
         min:                                    0.00
         avg:                                    0.07
         max:                                 2932.57
         95th percentile:                        0.00
         sum:                                67550.48

Threads fairness:
    events (avg/stddev):           50000.0000/13956.14
    execution time (avg/stddev):   3.3775/0.26
#+END_SRC

We can see that 1M rows whre added using a total of 43 INSERTs statements (an average of 23255.8 rows per INSERT). The total time was about 6.92 seconds.

The /latency/ statistics are interesting here, the /average/ time to insert a set of rows was 0.07 milliseconds, but max was way higher, about 2.9 seconds.
This is because the inserted rows are unevenly inserted among the tables, we can see this by comparing the fairness /stdev/ vs the /avg/.

After we are satisfied we can drop the tables, and be ready for the next test.

#+caption: cleanup drops the tables
#+BEGIN_SRC 
sysbench bulk_insert cleanup --threads=20
#+END_SRC

** OLTP read-only

OLTP (Online Transaction Processing) tests try simulate transaction-oriented loads in the database, sysbench does this by running several kinds of queries inside a transaction.

Lets start simple. We want to create 10 tables, each with 10K rows. For a total of 100K rows.

#+caption: prepare 10 tables, each has 10K rows
#+BEGIN_SRC 
# Prepare 10 tables, each with 10K rows 
sysbench oltp_read_only prepare --tables=10 --table_size=100000
#+END_SRC

It's usually a good idea to =prewarm= the database, i.e. load the tables into the buffer pool. So we can more acurately simulate the steady-state/warm performance.

#+caption: prewarm causes tables to be loaded in memory
#+BEGIN_SRC
sysbench oltp_read_only prewarm --tables=10 --threads=10
#+END_SRC

Run the benchmark with 10K events, with a ratio of 2 threads per table

#+caption: OTLP read only, 20 threads, no time limit
#+BEGIN_SRC  
sysbench oltp_read_only run --tables=10 --threads=20 --events=10000 --time=0

sysbench 1.0.15 (using system LuaJIT 2.0.5)

Running the test with following options:
Number of threads: 20
Initializing random number generator from current time


Initializing worker threads...

Threads started!

SQL statistics:
    queries performed:
        read:                            140000
        write:                           0
        other:                           20000
        total:                           160000
    transactions:                        10000  (1077.22 per sec.)
    queries:                             160000 (17235.59 per sec.)
    ignored errors:                      0      (0.00 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          9.2813s
    total number of events:              10000

Latency (ms):
         min:                                    4.37
         avg:                                   18.54
         max:                                   69.91
         95th percentile:                       29.19
         sum:                               185396.12

Threads fairness:
    events (avg/stddev):           500.0000/4.46
    execution time (avg/stddev):   9.2698/0.01
#+END_SRC

So, this is interesting: Why did we get 140K reads when we asked for 10K events? 

Sysbench by default runs the following statements per event:

- 10 x point selects: ~select c from table where id=i~
- 1 x simple range: ~select c from table where id between a and b~
- 1 x sum range: ~select sum(k) from table where id between a and b~
- 1 x order range: ~select c from table where id between a and b order by c~
- 1 x distinct range: ~select distinct c from table where id between a and b order by c~


#+caption: tidying up
#+BEGIN_SRC 
sysbench oltp_read_only cleanup --tables=20
#+END_SRC

Wasn't that fun?

** OLTP write only

This is the write counterpart of the previous test. By now, you know the drill, right?

#+caption: prepare and prewarm 10 tables
#+BEGIN_SRC  
sysbench oltp_write_only prepare --tables=10 
sysbench oltp_write_only prewarm --tables=10 --threads=10
#+END_SRC

To add variety, lets use a time limit instead:

#+caption: OTLP write only, 20 threads, 60 second limit
#+BEGIN_SRC
sysbench oltp_write_only run --tables=10 --threads=20 --events=0 --time=30
sysbench oltp_write_only cleanup --tables=10

sysbench 1.0.15 (using system LuaJIT 2.0.5)

Running the test with following options:
Number of threads: 20
Initializing random number generator from current time


Initializing worker threads...

Threads started!

SQL statistics:
    queries performed:
        read:                            0
        write:                           341181
        other:                           170918
        total:                           512099
    transactions:                        85123  (2836.18 per sec.)
    queries:                             512099 (17062.42 per sec.)
    ignored errors:                      672    (22.39 per sec.)
    reconnects:                          0      (0.00 per sec.)

General statistics:
    total time:                          30.0117s
    total number of events:              85123

Latency (ms):
         min:                                    0.53
         avg:                                    7.05
         max:                                   67.17
         95th percentile:                       14.21
         sum:                               599892.48

Threads fairness:
    events (avg/stddev):           4256.1500/49.08
    execution time (avg/stddev):   29.9946/0.00
#+END_SRC

Each write_only event consists of:

- 1 x index_updates: ~update table set k~k+1 where id=i~
- 1 x non_index_updates: ~update table set c=? where id=i~
- 1 x delete_inserts: ~delete from table where id~i; insert into table (id, k, c, pad) values (...)~

When using a time stop condition, we'll want to compare rates, such as /queries per second/ or /transactions per second/

** OLTP read write

This test combines the last two in one package. First it runs the same code as in oltp_read_only and then continues with oltp_write_only.
We can even reuse the table from the previous benchmark.

The transaction content for tests can be tweaked.

#+caption: fine tuning options for transaction content
#+BEGIN_SRC 
--range_selects[=on|off]      Enable/disable all range SELECT queries [on]
--range_size=N                Range size for range SELECT queries [100]
--simple_ranges=N             Number of simple range SELECT queries per transaction [1]
--point_selects=N             Number of point SELECT queries per transaction [10]
--order_ranges=N              Number of SELECT ORDER BY queries per transaction [1]
--distinct_ranges=N           Number of SELECT DISTINCT queries per transaction [1]
--delete_inserts=N            Number of DELETE/INSERT combinations per transaction [1]
--index_updates=N             Number of UPDATE index queries per transaction [1]
--non_index_updates=N         Number of UPDATE non-index queries per transaction [1]
--sum_ranges=N                Number of SELECT SUM() queries per transaction [1]
--skip_trx[=on|off]           Don't start explicit transactions and execute all queries in the AUTOCOMMIT mode [off]
#+END_SRC

** Conclusion

These aren't the only DB tests that ship with sysbench, but the basic procedure doesn't change. Unfortunately there isn't any command to get a list of the available tests, 
but you can search for .lua files in your sysbench install dir.

* TODO MySQLSlap (part 1)                                     :mysql:guides:
:PROPERTIES:
:EXPORT_FILE_NAME: mysqlslap-part1
:END:

Today I want to talk one about a the original benchmark tool for mysql: mysqlslap, self-described as "Load Emulation Client". 
It fist appeared circa MySQL 5.1, so by now, its age must be past the single digits. It is still bundled with client program in MySQL and MariaDB.

In this post I'll cover the basics and the /automatic/ mode, be sure to read the second part [LINK] which is about the (more instersting) /custom/ mode.

** How does it work?

mysqlslap uses the same connection parameters as the normal mysql client, so ~--host~ ~--port~ ~--socket~ ~--username~ ~--password~ works (but strangely not the ~--defaults-file~). 
In the examples below the parameters /will be omitted/ for brevity's sake.

mysqlslap has three stages: 

1. create test schema
2. run test as multiple clients
3. delete test schema.
 
The first and last are executed as a single connection, only the second step time is measured.

** The automatic mode
   :LOGBOOK:
   CLOCK: [2018-12-03 Mon 12:14]--[2018-12-03 Mon 12:34] =>  0:20
   :END:

In automatic mode, mysqlslap will handle table and queries. No need to write any SQL text.

This mode enabled with the ~--auto-generate-sql~ (or in short form: ~-a~) parameter.

#+caption: mysqlslap in action
#+BEGIN_SRC 
mysqlslap --auto-generate-sql --auto-generate-sql-load-type=read --auto-generate-sql-execute-number=10
Benchmark
        Average number of seconds to run all queries: 0.004 seconds
        Minimum number of seconds to run all queries: 0.004 seconds
        Maximum number of seconds to run all queries: 0.004 seconds
        Number of clients running queries: 1
        Average number of queries per client: 10
#+END_SRC

What did it do?

1. It created ~mysqlslap~ schema
2. It created a test table ~t1~ with 1 integer and 1 varchar(128) column, no explicit primary key
3. It populated it with random rows.
4. A full table SELECT is run 10 times, sequentially, from a single connection
5. The ~mysqlslap~ schema is dropped
6. The total time taken reported

Let's break down the options
#+BEGIN_SRC 
--auto-generate-sql-load-type        what is the test type to run
--auto-generate-sql-execute-number   how many queries to execute *per client*
#+END_SRC

Let's try another one

#+caption: mysqlslap with 10 clients
#+BEGIN_SRC 
mysqlslap --auto-generate-sql --auto-generate-sql-load-type=read --auto-generate-sql-execute-number=1 --concurrency=10
Benchmark
        Average number of seconds to run all queries: 0.015 seconds
        Minimum number of seconds to run all queries: 0.015 seconds
        Maximum number of seconds to run all queries: 0.015 seconds
        Number of clients running queries: 10
        Average number of queries per client: 1
#+END_SRC

This one runs the same total number of SELECTs as before, but in parallel, we have 10 clients running the a single query. We get the total taken to run the 10 queries.

Did you notice the times reported? Why do we get the same values for average, max and min?
This is because so far we ran the test only 1 time. We can choose to repeat the test using then ~--iterations~ parameter.

#+caption: 10 clients, 100 interations 
#+BEGIN_SRC 
mysqlslap --auto-generate-sql --auto-generate-sql-load-type=read --auto-generate-sql-execute-number=1 --concurrency=10 --iterations=100
Benchmark
        Average number of seconds to run all queries: 0.006 seconds
        Minimum number of seconds to run all queries: 0.001 seconds
        Maximum number of seconds to run all queries: 0.015 seconds
        Number of clients running queries: 10
        Average number of queries per client: 1
#+END_SRC

What is the difference?
Essentially the whole thing (with its schema creaation and deletion) is executed 100 times. 
Now times are different because we added some variability.

** So what other things can we do?

We can try other types of tests, =--auto-generate-sql-load-type= can take the following values

- read: ~SELECT * FROM table~
- write: ~INSERT~
- key: ~SELECT (primary keys columns)~
- update: ~UPDATE (primary keys)~
- mixed: ~INSERT and SELECT * 

The mixed mode is the default, it generates 2 queries and both count towards the =--auto-generate-sql-execute-number=

#+caption: the mixed mode runs 5 inserts and 5 selects
#+BEGIN_SRC 
mysqlslap --auto-generate-sql --auto-generate-sql-execute-number=10
Benchmark
        Average number of seconds to run all queries: 0.006 seconds
        Minimum number of seconds to run all queries: 0.006 seconds
        Maximum number of seconds to run all queries: 0.006 seconds
        Number of clients running queries: 1
        Average number of queries per client: 10
#+END_SRC

Can you guess what has mysqlslap done? 
It ran the mixed load test, and since we asked to generate 10 queries it executed 5 INSERTS and 5 SELECTs. We get the total time to run all the queries.

The generated table can be tweaked with the following options:

#+BEGIN_SRC 
--number-char-cols   number of varchar columns (1)
--number-int-cols    number of integer columns (1)
--auto-generate-sql-guid-primary        add a varchar(36) primary column (none)
--auto-generate-sql-add-autoincrement   add an autoincrement bigint column with an unique index (none)
--auto-generate-sql-secondary-indexes   generate n integer columns with unique indexes (0)
#+END_SRC

The table contents can be further tweaked.

#+BEGIN_SRC 
--auto-generate-sql-write-number         how many rows to insert into test table (100)
--auto-generate-sql-unique-query-number  how many unique rows, so we can play with cardinality (10)
#+END_SRC

By default we should have a 10 unique rows repeated 10 times.

Other useful options:

#+BEGIN_SRC 
-vv        show verbose output
--csv      output into csv file
--no-drop         don't drop the schema when done
--create-schema   change the test schema, it will be DROPed afterwards (unless --no-drop)
#+END_SRC

** Conclusion

mysqlslap is an arguably basic benchmarking tool, but I find it very useful for quick tests. 
And since we can almost always count on having it installed it's a good idea to get familiarized with it. 
The next part will cover the custom query mode. [LINK]

* TODO MySQLSlap (part 2)                                     :mysql:guides:
:PROPERTIES:
:EXPORT_FILE_NAME: mysqlslap-part2
:END:

This is the second part of my mysqlslap guide, you can read the first part here [LINK]

** The custom query mode

This mode allow us to benchmark ad-hoc queries, it's a quick way to troubleshoot individual query performance.

In its simplest form we pass the query to test:

(Remember that the connection parameters are /omitted/ here for brevity's sake, for a short explanation check part1) [LINK]

#+caption: a simple ad-hoc benchmark
#+BEGIN_SRC
mysqlslap --query="call superheroes.secret_identity('batman');"
  Benchmark
          Average number of seconds to run all queries: 0.000 seconds
          Minimum number of seconds to run all queries: 0.000 seconds
          Maximum number of seconds to run all queries: 0.000 seconds
          Number of clients running queries: 1
          Average number of queries per client: 1
#+END_SRC

We can also write our SQL text in a file. mysqlslap is quirky when parsing files, it expects each statement into its own line, we can regain the normal behaviour using =--delimiter=

#+caption: read query from a file
#+BEGIN_SRC 
mysqlslap --query='my_query.sql' --delimiter=';'
#+END_SRC

If we want to repeat the query 10 times we use ~--iterations~. mysqlslap opens 1 connection and runs the query 10 times sequentially

#+caption: example of iterations
#+BEGIN_SRC 
mysqlslap --iterations=10 --query="SELECT sleep(0.1);"
Benchmark
        Average number of seconds to run all queries: 0.102 seconds
        Minimum number of seconds to run all queries: 0.101 seconds
        Maximum number of seconds to run all queries: 0.104 seconds
        Number of clients running queries: 1
        Average number of queries per client: 1
#+END_SRC

The average time for each query was 0.101. The total execution time unfortunately is not shown by the tool but was a little longer than 1 second.

We can also use ~--concurrency~ to simulate many clients running at the same time. For example to simulate 20 clients, each one running time the query one time:

#+caption: example of concurrency
#+BEGIN_SRC 
mysqlslap --concurrency=20 --query="SELECT sleep(0.1);"
Benchmark
        Average number of seconds to run all queries: 0.107 seconds
        Minimum number of seconds to run all queries: 0.107 seconds
        Maximum number of seconds to run all queries: 0.107 seconds
        Number of clients running queries: 20
        Average number of queries per client: 1
#+END_SRC

This time the command returned after a little longer than 100 ms, because the sleep was concurrent, so it exited after the last client finished sleeping.

And we can combine concurrency and iterations, this will run the query a total of 200 times:

#+caption: concurrency and iterations
#+BEGIN_SRC 
mysqlslap --concurrency=20 --iterations=10 --query="SELECT sleep(0.1);"
Benchmark
        Average number of seconds to run all queries: 0.111 seconds
        Minimum number of seconds to run all queries: 0.104 seconds
        Maximum number of seconds to run all queries: 0.121 seconds
        Number of clients running queries: 20
        Average number of queries per client: 1
#+END_SRC

Total run time a little longer than 1 second.

What about if we want to create the test data? mysqlslap provides the =--create-schema= and the =--create= parameters. 
*A word of warning*, the schema will be dropped afterwards (unless we supply =--no-drop=).
 We can supply the create DDL text as strings or inside a text file:

#+caption: create test schema from file, drop it when finished
#+BEGIN_SRC 
mysqlslap --query="select * from heroes;" --create-schema='superheroes' --create='schema.sql' --delimiter=";"
#+END_SRC

** Conclusion

If you haven't already, check the first part of my guide to mysqlslap [LINK]. 
I haven't covered all the options, only the ones I find myself using more frequently.
You can check the full manual on the mysql's docs. [LINK]

* TODO Unused index cleanup                               :mysql:tuning:
:PROPERTIES:
:EXPORT_FILE_NAME: unused-index-cleanup
:END:

I love indexes: they speed up my queries, they let me make quicker joins, they are, in one word: neat. Undoubtedly relational databases would be infeasible without them.

But what happens when indexes are left unused? Maybe application requirements or the workload changed. Maybe someone was toying with indexes in the hope to speed up some pesky query. Whatever the reasons periodically we'll need to identify and remove them.

#+hugo: more

Indexes also have a dark side: they penalize writes. With a side dish of taking additional disk space. Most of the times the benefits greatly surpasses these downsides.

** Finding unused indexes in MySQL

Since MySQL 5.6 we have two great tools: the *performance_schema*, which collects a lot of nice metrics and the *sys* schema which offers easy-to-read views.

The first thing to do is ensure that performance_schema is enabled and configured. There is a lot to say about configuring the performance schema, but for now it is enough using the MySQL Workbench "Performance Schema Setup": it should be set to at least the "Server Default" level.

#+caption: easy mode setup
[[/images/performance_schema_easy_mode.png]]

Once everything is set up, we'll be using this:

~select * from sys.schema_unused_indexes~

> The [[https://dev.mysql.com/doc/refman/5.7/en/sys-schema-unused-indexes.html][schema_unused_indexes View]]
>
> These views display indexes for which there are no events, which indicates that they are not being used. By default, rows are sorted by schema and table.
>
> This view is most useful when the server has been up and processing long enough that its workload is representative. Otherwise, presence of an index in this view may not be meaningful. 

And here is the catch: at first glance it seems that we need to ensure that the server has been running for some time, i.e. the performance counters are 
reset on service restart. But I found that this is not enough, because all the counters are also reset *if any index on that table is modified*

That's right. Running an ~alter table add|remove index~, marks all the other indexes on that table table as unused.

I found this behaviour in both MySQL and MariaDB. If you wish to have some fun test it yourself:

#+caption: Testing schema_unused_indexes
#+begin_src sql
create database super;
create table super.heroes (
	name varchar(45) not null,
	hability varchar(45) not null,
	key(name),
	key(hability)
);
insert into super.heroes values
('the flash','speed'),
('aquaman','fish language'),
('batman','rich'),
('superman','all of them');

-- use the index and check the counters
select name from super.heroes;
select * from sys.schema_unused_indexes;

-- any one of these resets the index usage counters
alter table super.heroes add key name_hability(name,hability);
alter table super.heroes drop key name_hability;
#+end_src

** Conclusion

Here's my general strategy:

1. Backup the tables or at the very least export the index definitions
2. Ensure that both server has been running for enough time *AND* that the table has not been modified recently
 
  =show table status from <SCHEMA> where name = <TABLE>;=  

3. Save the list of the unused indexes somewhere safe, you'll probably lose it after modifying the table
 
  ~create table unused_backup as select * from sys.schema_unused_indexes;~
 
4. Delete the unused indexes

Cheers

* TODO Linux utilization with sysstat                                 :guide:
:PROPERTIES:
:EXPORT_FILE_NAME: linux-monitoring
:END:

--> http://sebastien.godard.pagesperso-orange.fr/tutorial.html
--/
sysstat includes: pidstat vmstat sar iostat ?
/usr/bin/cifsiostat
/usr/bin/iostat
/usr/bin/mpstat
/usr/bin/pidstat
/usr/bin/sadf
/usr/bin/sar
/usr/bin/tapestat
/usr/lib64/sa/sa1
/usr/lib64/sa/sa2

export S_COLORS=auto

sar -u
The %user and %system columns simply specify the amount of time the CPU spends in user and system mode. 
The %iowait and %idle columns are of interest to us when doing performance analysis. 
The %iowait column specifies the amount of time the CPU spends waiting for I/O requests to complete.
The %idle column tells us how much useful work the CPU is doing. A %idle time near zero indicates a CPU bottleneck, while a high %iowait value indicates unsatisfactory disk performance.
Additional information can be obtained by the sar -q command, which displays the run queue length, 
total number of processes,  and the load averages for the past one, five and fifteen minutes:

Linux 2.6.8.1-27mdkcustom (localhost)   03/29/2006

09:00:00 PM   runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-15
09:10:00 PM         2       121      2.22      2.17      1.45
09:20:00 PM         6       137      2.79      2.48      1.73
09:30:00 PM         5       129      3.31      2.83      1.95

This example shows that the system is busy (since more than one process is runnable at any given time) and rather overloaded. 
sar also lets you monitor memory utilization. Have a look at the following example produced by sar -r:


kernel counters -> sar calculates rates and ratios
-o interactive mode

pidstat -d 
shows proceses with heavy io
-t thread tree?
-r memory per process (memory leak)

# Run system activity accounting tool every 10 minutes
*/10 * * * * root /usr/lib/sa/sa1 -d 1 1
# 0 * * * * root /usr/lib/sa/sa1 -d 600 6 &
# Generate a daily summary of process accounting at 23:53
53 23 * * * root /usr/lib/sa/sa2 -A


--\


When I started working with Linux I was dazzled and befuddled by the sheer amount of performance information available.
So many tools, so many files to cat, so much misterious numbers.
I also was dissapointed because things seemed so hard, even in Windows there was a couple of simple tools that,
while not pretty, where capable and even made plots.

With time and cutting of teeth, I found my way around the Linux ecosystem. There are some very good tools. 
In this post I want to talk the [[http://sebastien.godard.pagesperso-orange.fr/tutorial.html][systat]] package.

systat includes a few fundamental tools like vmstat, iostat, mpstat and sar. It also includes some more specific utilities
like cifsiostat and tapestat.


** vmstat

This one I initially underrated, because I didn't know better. Today I couldn't live without it.
Fortunately it's included in most linux, even if systat package isn't installed, so I don't.

vmstat and top are the almost always the first thing to check when the server slow. 
It does a little bit of everything: memory, processes, I/O, swap, disks, CPU. We get a feel of the overal picture.

We can get the overall system stats with ~-s~

#+caption: vmstat stats
#+BEGIN_SRC 
vmstat -s 
     11688288 K total memory
      4822840 K used memory
      6800416 K active memory
      2252240 K inactive memory
      1733492 K free memory
       847604 K buffer memory
      4284352 K swap cache
      5859368 K total swap
            0 K used swap
      5859368 K free swap
      1727696 non-nice user cpu ticks
         4417 nice user cpu ticks
       642987 system cpu ticks
     11128500 idle cpu ticks
         4221 IO-wait cpu ticks
       114956 IRQ cpu ticks
        37594 softirq cpu ticks
            0 stolen cpu ticks
      3409651 pages paged in
      5443400 pages paged out
            0 pages swapped in
            0 pages swapped out
     72814505 interrupts
    269672233 CPU context switches
   1545570636 boot time
        85754 forks
#+END_SRC

And disk we get a summary we use ~-D~

#+caption: disk stats
#+BEGIN_SRC 
vmstat -D
            2 disks 
            3 partitions 
       550524 total reads
         7692 merged reads
     13624112 read sectors
       178377 milli reading
       580149 writes
       102407 merged writes
     22761960 written sectors
      1330855 milli writing
            0 inprogress IO
          255 milli spent IO
#+END_SRC

They best feature, though, is that it supports a sampling /interval/ and an optional stop after /count/ samples.
With these we get a table output, with a new row printed every /interval/ seconds. 

~vmstat INTERVAL COUNT~

#+caption: vmstat 1 second interval, print 7 samples
#+BEGIN_SRC 
vmstat 1 7
procs   -----------memory----------   --swap-    ---io--- -system-- ------cpu-----
 r  b   swpd    free   buff  cache    si   so    bi    bo   in   cs us sy id wa st
 4  0      0 4098084 375068 3462944    0    0    34    25  340  320  8  3 89  0  0
 1  0      0 4098184 375068 3463264    0    0     0     0 1263 3198  4  3 93  0  0
 0  0      0 4098436 375068 3462924    0    0     0     0 1141 2999  3  2 95  0  0
 0  0      0 4098240 375068 3462924    0    0     0     0 1013 2794  4  3 93  0  0
 0  0      0 4097988 375076 3462916    0    0     0    52 1569 4012  4  2 94  0  0
 0  0      0 4097736 375076 3462916    0    0     0     0 2166 4414  5  4 92  0  0
 0  0      0 4096476 375076 3462916    0    0     0     0 1103 3130  3  3 94  0  0
#+END_SRC

All values, with the exception of memory and processes, are /averages/ or /deltas/ since the previous sample. 
The very first row shows the averages since boot. 
Memory and processes (the first 6 columns) are always instantaneous values. 
Memory is shown in KBs, but we can change the units with ~-S~, e.g. ~-S M~ for MBs.
If your version of vmstat supports the ~-w~ option, use it because it makes the table wider and easier to read.

So what does each column mean:

| column | meaning | units |
| r | number of processes running | - |
| b | number of processess sleeping | - |
| spwd | swap memory used | K |
| free | free or idle memory | K |
| buff | memory used for buffers | K |
| cache | memory used for cache | K |
| si | amount swapped from disk to memory     | page |
| so | amount swapped to disk from memory | page |
| bi | number of blocks received from block device | block |
| bo | number of blocks written to block device | block |
| in | interrups per second | 1/s |
| cs | context switches per second | 1/s |
| us | CPU user time | % of total |
| sy | CPU system time | % of total | 
| id | CPU idle time | % of total |
| st | CPU time stolen from Virtual Machine | % of total |

A few guidelines to read the table

- a high number of processes sleeping means there is probably some blocking or locks going on
- check si and so for swapping activity, swapping is the performance-killer
- check that memory allocation makes sense for the workload
- consistent high /us/ values indicate CPU bound load
- consistent high /wa/ values indicate I/O bound load
- when running on a virtuale machine, if /st/ is consistently high for long the machine could be underprovisioned or the VM host is overloaded

With the ~-d~ option we get a per-device I/O counters

#+caption: disk activity per device, 1 update per second, 7 samples
#+BEGIN_SRC 
vmstat -d 1 7
disk- ------------reads------------ ------------writes----------- -----IO------
       total merged sectors      ms  total merged sectors      ms    cur    sec
sda   154968   4762 5471678   52614 123981  67290 4139296   68873      0     45
sda   154968   4762 5471678   52614 123985  67305 4139440   68876      0     45
sda   154968   4762 5471678   52614 123985  67305 4139440   68876      0     45
sda   187408   5295 5735598   57872 125026  67646 4175256   70037      0     49
sda   187408   5295 5735598   57872 125329  67670 4416176   71538      0     50
sda   187412   5295 5735630   57902 126243  67670 5887824   80143      0     51
sda   187412   5295 5735630   57902 126252  67704 5888256   80177      0     51
#+END_SRC

The columns are read like this:

| column | meaning |
| total | total number of reads / writes |
| merged | merged requests (N requests into one I/O) |
| sectores | number of sectores read / written |
| ms | milliseconds spent reading / writting |
| cur | number of I/O operations running |
| s | seconds spent for I/O |

All the values are /totals/ since last boot.

Another option is ~-p~, that prints per paritition activity

#+caption: disk activity per device, 1 update per second, 7 samples
#+BEGIN_SRC 
vmstat -p /dev/sda1
sda1            reads      read sectors      writes  requested writes
                  163              9050           3                24
#+END_SRC

We can also access a detailed cache utilization report with ~-m~, but it needs root permissions to work. 
Here we can also use an /interval/ and /count/, the list will probably exceed one page of the terminal though.

#+caption: slab mode, requires root permission
#+BEGIN_SRC 
sudo vmstat -m        
Cache                            Num  Total   Size  Pages
ecryptfs_inode_cache            1544   1564    960     17
ecryptfs_file_cache              256   1024     16    256
ecryptfs_auth_tok_list_item       19     76    832     19
nf_conntrack_expect                0      0    216     18
nf_conntrack                     101    200    320     25
fuse_request                      80     80    400     20
fuse_inode                        42     76    832     19
ext4_groupinfo_4k               1716   1736    144     28
ext4_inode_cache              325004 327150   1080     30
ext4_allocation_context          128    128    128     32
ext4_io_end                      256    320     64     64
ext4_extent_status            156920 156978     40    102
mbcache                          294    438     56     73
..... elipsised .....
#+END_SRC

Here the columns are:

| column | meaning |
| cache | the cache name |
| num | active object count |
| total | total object count |
| size | size per object |
| pages | pages with one or more active object |

** iostat

iostat shows combined /instantaneous/ CPU and disk activity. As with vmstat, we can supply optional /interval/ and /count/

#+caption: CPU + block device activity, 1 update per second
#+BEGIN_SRC 
iostat 1       
Linux 4.19.8-arch1-1-ARCH (ix) 	12/24/2018 	_x86_64_	(4 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          12.14    0.03    5.66    0.03    0.00   82.14

Device             tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               4.41        29.11        49.44    3409859    5790640

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           5.56    0.00    3.79    0.00    0.00   90.66

Device             tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               0.00         0.00         0.00          0          0
... elipsised ...
#+END_SRC

We can choose to only see cpu with ~-c~ or disk with ~-d~. ~-x~ shows extended I/O statistics, ~-m~ changes units to MB,
~-h~ shows an easier to read report. These are some of the many additional formatting options. 

** mpstat

mpstat shows (more) detailed CPU statistics. We get vmstat's coiunters plus some. 

#+caption: cpu activity with mpstat, 1 sample per second
#+BEGIN_SRC 
mpstat 1
Linux 4.19.8-arch1-1-ARCH (ix) 	12/24/2018 	_x86_64_	(4 CPU)

06:48:41 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
06:48:42 PM  all    7.85    0.00    3.04    0.00    0.25    0.51    0.00    0.00    0.00   88.35
06:48:43 PM  all   10.08    0.00    4.79    0.00    1.01    0.00    0.00    0.00    0.00   84.13
06:48:44 PM  all    7.25    0.00    5.25    0.00    0.75    0.50    0.00    0.00    0.00   86.25
06:48:45 PM  all    9.07    0.00    3.78    0.25    1.01    0.50    0.00    0.00    0.00   85.39
#+END_SRC

We can choose to only show activity for some CPUs with ~-P~, e.g. ~-P 1,3~

There are additional views: ~-I ALL~ shows all CPU interruptions, ~-n~ shows CPU statistics based on NUMA placement nodes
(use ~-N~ to indicate which nodes to report). There is even a JSON output with ~-o JSON~

** pidstat

This one is similar to /top/ in batch mode, i.e. pidstat is not interactive.

We can get a list of processes running on each sampling /interval/. Or we can only track some of them in particular with
~-p~.

#+caption: pidstat tracking a MySQL process
#+BEGIN_SRC 
pidstat -p 25809  1 5
Linux 4.19.8-arch1-1-ARCH (ix) 	12/25/2018 	_x86_64_	(4 CPU)

11:22:54 AM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
11:22:55 AM   980     25809   41.00   25.00    0.00    0.00   66.00     3  mysqld
11:22:56 AM   980     25809   47.00   24.00    0.00    0.00   71.00     3  mysqld
11:22:57 AM   980     25809   47.00   22.00    0.00    0.00   69.00     3  mysqld
11:22:58 AM   980     25809   48.00   21.00    0.00    0.00   69.00     3  mysqld
11:22:59 AM   980     25809   40.00   29.00    0.00    0.00   69.00     3  mysqld
Average:      980     25809   44.60   24.20    0.00    0.00   68.80     -  mysqld
#+END_SRC

pidstat can also start a program ~-e~ and track it over its execution.

Besides CPU, pidstat can also show per process I/O statistics:

#+caption: I/O statistics for a single process
#+BEGIN_SRC 
pidstat -p 29077 -d 1 5
Linux 4.19.8-arch1-1-ARCH (ix) 	12/28/2018 	_x86_64_	(4 CPU)

02:19:11 PM   UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
02:19:12 PM  1000     29077      0.00 227184.00      0.00       0  dd
02:19:13 PM  1000     29077      0.00 222172.00      0.00       0  dd
02:19:14 PM  1000     29077      0.00 217484.00      0.00       0  dd
02:19:15 PM  1000     29077      0.00 193916.83      0.00       0  dd
02:19:16 PM  1000     29077      0.00 163200.00      0.00       0  dd
#+END_SRC

pidstat supports all these views:

#+caption: pidstat modes
#+BEGIN_SRC 
-u CPU statistics
-d I/O statistics
-R process priority
-r memory utilization
-s stack utilization
-t thread statistics
-w task switching
-v file descriptor utilization
#+END_SRC

** sar

sar takes a different route, it collects system activity and lets you browse and filter at your leisure.

*** Automatic mode

To run the automatic collection periodically we can create a cron entry. Alternatively we could use a systemd timer.

#+caption: cron entry, 1 sample every 10 minutes, collect additional disk statistics
#+BEGIN_SRC
@reboot /usr/lib/sa/sa1 --boot
*/10 * * * * /usr/lib/sa/sa1 1 1 -S DISK
#+END_SRC

The @reboot line is kind of optional, but if your cron supports it's good to have since it ensures the counters are reset
on boot.

sa1 is just a script that calls ~sadc~. sadc does the actual collecting, to prevent the files for growing too large
not everything is stored, thus some optional counters must be enabled with the ~-S~ option.

- DISK block devices
- XDISK block devices and partitions
- INT system interrupts
- IPV6 network IPV6 statistics
- POWER power management
- SNMP is for the SNMP statistics
- ALL everything except XDISK
- XALL everthing including XDISK

sa1's config is usually located in /etc/conf.d/sysstat or /etc/default/sysstat. Here there are the retention and path defaultHere there are the retention and path defaults.

To access the data we have two options, first we can use the sa2 script which generates yesterday's activity text report
(in /var/log/sarNN). This can be croned easily:

#+caption: cron for daily text report, based on yesterday's activity
#+BEGIN_SRC 
00 18 * * * /usr/lib/sa/sa2 -A
#+END_SRC

Alternatively we can call sar directly, this lets us choose what to see.

#+caption: all sar views, extended options
#+BEGIN_SRC 
-b        I/O rates
-d        block device activity
-F        mounted filesystem statistics
-n ALL    network statistics
-P ALL    per processor statistics
-u [ALL]  CPU utilization
-q        queue and load average
-r [ALL]  memory utilization
-H        hugepages utilization
-S        swap space utilization
-B        paging statistics
-W        swapping activity
-v        inode and kernel tables
-w        task/process creation 
-y        TTY device activity
-m ALL    power management statistics
-I ALL    interrupts
-A        Everything
#+END_SRC

Some views have additional options, for example ~-n ALL~ shows all network activity (including protocols) while ~-n DEV~
only shows network devices.

sar shows by default today's data, but using ~-1~ there is yesterday's, ~-2~ for the day before yesterday and so on.
We can specify the starting time with ~-s~ (HH:MM:SS)

#+caption: yesterday's cron collected metrics, 10 samples every 5 seconds
#+BEGIN_SRC 
sar -1 5 10
Linux 4.19.8-arch1-1-ARCH (ix) 	12/26/2018 	_x86_64_	(4 CPU)

02:58:05 PM     CPU     %user     %nice   %system   %iowait    %steal     %idle
02:58:10 PM     all     10.89      0.00      7.82      0.00      0.00     81.29
02:58:15 PM     all      9.82      0.00      7.35      0.00      0.00     82.83
02:58:20 PM     all     11.28      0.00      6.33      0.05      0.00     82.34
02:58:25 PM     all     10.69      0.00      7.06      0.05      0.00     82.21
02:58:30 PM     all     10.27      0.00      7.02      0.00      0.00     82.71
02:58:35 PM     all     11.49      0.00      8.22      0.00      0.00     80.30
02:58:40 PM     all     11.90      0.00      6.66      0.05      0.00     81.39
02:58:45 PM     all     14.38      0.00      7.14      0.05      0.00     78.43
02:58:50 PM     all     10.66      0.00      6.63      0.00      0.00     82.71
02:58:55 PM     all     15.01      0.00      6.63      0.00      0.00     78.35
Average:        all     11.63      0.00      7.09      0.02      0.00     81.26

#+END_SRC

*** Interactive mode

sar works interactively too, which is nice when a quick snapshot is needed. Maybe while testing something
or doing a benchmark. With the ~-o~ option, sar stores/appends data in a file or directory.

sar takes a sampling /interval/ (in seconds) and /count/ that works as a stop condition.

#+caption: collect everything, every second, 1 minute duration, store in my_metrics file
#+BEGIN_SRC 
sar -o my_metrics 1 60
Linux 4.19.8-arch1-1-ARCH (ix) 	12/24/2018 	_x86_64_	(4 CPU)

07:01:06 PM     CPU     %user     %nice   %system   %iowait    %steal     %idle
07:01:07 PM     all     11.08      0.00      4.79      0.00      0.00     84.13
07:01:08 PM     all     13.71      0.00      7.11      0.25      0.00     78.93
07:01:09 PM     all     13.62      0.00      6.43      0.00      0.00     79.95
07:01:10 PM     all     13.99      0.00      6.36      0.00      0.00     79.64
...
#+END_SRC

Does the output sounds familiar? If it does great, I've not yet managed to bore you to tears. 
The output is mpstat's, in fact sar comes bundled with mpstat, pidstat, vmstat and iostat.

To retrieve the results we use ~-f~.
We can use a different INTERVAL or COUNT and the output is filtered appropiately.

#+caption: read collected data from my_metrics file
#+BEGIN_SRC 
sar -f my_metrics -s 14:00:00 1 5
Linux 4.19.8-arch1-1-ARCH (ix) 	12/24/2018 	_x86_64_	(4 CPU)

14:00:00 PM     CPU     %user     %nice   %system   %iowait    %steal     %idle
14:00:01 PM     all      9.47      0.00      6.01      0.00      0.00     84.52
14:00:02 PM     all     11.11      0.00      5.05      0.00      0.00     83.84
14:00:03 PM     all     29.62      0.00      9.87      0.00      0.00     60.51
14:00:04 PM     all     12.85      0.00      3.27      0.00      0.00     83.88
14:00:05 PM     all     20.00      0.00      8.86      0.00      0.00     71.14
Average:        all     16.09      0.00      6.57      0.00      0.00     77.35
#+END_SRC

#+caption: sar showing memory results
#+BEGIN_SRC 
sar -r -f my_metrics
Linux 4.19.8-arch1-1-ARCH (ix) 	12/24/2018 	_x86_64_	(4 CPU)

07:45:47 PM kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
07:45:48 PM    755544   5216144   5525576     47.27    876804   3773928  14648100     83.48   7714540   2267792      4404
07:45:49 PM    753728   5214328   5527772     47.29    876804   3773548  14648100     83.48   7716816   2267400      4420
07:45:50 PM    734512   5195136   5546088     47.45    876804   3774448  14651412     83.49   7734560   2268308      4432
07:45:51 PM    717524   5178164   5562876     47.59    876804   3774648  14670976     83.61   7750836   2268504      4448
07:45:52 PM    711580   5172232   5568900     47.65    876804   3774568  14670976     83.61   7757748   2268428      4460
Average:       734578   5195201   5546242     47.45    876804   3774228  14657913     83.53   7734900   2268086      4433
#+END_SRC

** sadf

Wouldn't it be great to be able to export sar's data? Maybe to a database or a spreasheet?
Wouldn't it be cool to have plots? No worries, sadf has you covered.

The basic usage for sadf is:

#+hugo_base_dir: ./blog
#+hugo_section: posts
#+author: Tom

--> it's all about the data !


* Recycle?
** NOTAS METRIC
cpu+mem: vmstat -w -n -t 1 | tail -n +3
disk: vmstat -w -d -t 1


CPU
vmstat 1
vmstat reports information about processes, memory, paging, block IO, traps, disks
       and cpu activity

FIELD DESCRIPTION FOR VM MODE
   Procs
       r: The number of runnable processes (running or waiting for run time).
       b: The number of processes in uninterruptible sleep.

   Memory
       swpd: the amount of virtual memory used.
       free: the amount of idle memory.
       buff: the amount of memory used as buffers.
       cache: the amount of memory used as cache.
       inact: the amount of inactive memory.  (-a option)
       active: the amount of active memory.  (-a option)

   Swap
       si: Amount of memory swapped in from disk (/s).
       so: Amount of memory swapped to disk (/s).

   IO
       bi: Blocks received from a block device (blocks/s).
       bo: Blocks sent to a block device (blocks/s).

   System
       in: The number of interrupts per second, including the clock.
       cs: The number of context switches per second.

   CPU
       These are percentages of total CPU time.
       us: Time spent running non-kernel code.  (user time, including nice time)
       sy: Time spent running kernel code.  (system time)
       id: Time spent idle.  Prior to Linux 2.5.41, this includes IO-wait time.
       wa: Time spent waiting for IO.  Prior to Linux 2.5.41, included in idle.
       st: Time stolen from a virtual machine.  Prior to Linux 2.6.11, unknown.

FIELD DESCRIPTION FOR DISK MODE
   Reads
       total: Total reads completed successfully
       merged: grouped reads (resulting in one I/O)
       sectors: Sectors read successfully
       ms: milliseconds spent reading

   Writes
       total: Total writes completed successfully
       merged: grouped writes (resulting in one I/O)
       sectors: Sectors written successfully
       ms: milliseconds spent writing

   IO
       cur: I/O in progress
       s: seconds spent for I/O

FIELD DESCRIPTION FOR SLAB MODE
       cache: Cache name
       num: Number of currently active objects
       total: Total number of available objects
       size: Size of each object
       pages: Number of pages with at least one active object

** PREP
*** vmstat
http://blog.scoutapp.com/articles/2013/07/25/understanding-cpu-steal-time-when-should-you-be-worried
st: steal time VM, also in top, check on a virtual/cloud environment
Steal time is the percentage of time a virtual CPU waits for a real CPU while the hypervisor is servicing another virtual processor.
id: idle
wa: I/O wait

sysstat= iostat+mpstat+sar

sar -u 1

sar [-o repo] interval count 

sar [-f repo] [switches] interval count

network -n DEV --iface=wlp4s0
power management -m 
mounted -F
block devices -d
paging -B
i/o rates -b
memory utilization -r
swap utilization -S
cpu utilization -u
inode status -v
swapping -W
task creation -w
tty activity -y

- sar -P ALLwlp4s0
- dstat -c 
- mpstat -P ALL
- top/htop

MEM

vmstat -s
free
cat /proc/meminfo

slab
  vmstat -s 
  slabtop -s -c

DISK
vmstat -d 1

- free
- vmstat
- dstat -m,"free"
- sar -r,"%memused%"

 
- iotop
- iostat
- perf?

DB
- innotop?
* Recycle Bin

# Would you buy a car or a bike without giving it a test drive? I sure wouldn't. 
# Unfortunately we can't always check what's under the hood before buying hardware, provisioning a VPS or a cloud machine.
# But we can benchmark it, find its capabilities, and hopefully check that is fits our needs.
# :: Is my server fast? How fast is fast? The answers are, of course, relative. 
# If you are planning in writing your own tests or downloading some you'll probably also want to install [[https://luarocks.org/][luarocks]] for additional lua packages. There is a also
# *If both --time and --events are 0, some tests may run forever*
# ** Why bother?
# ** Extending sysbench

With a little bit knowledge of Lua [LINK], we can write our own test. In addition you can download lua modules and additional sysbench tests. 

For downloading additional modules it's recommended to install =luarocks= which handles lua packages. There is an specialized luarocks repository for sysbench [LINK]

By default sybench will first check for the test scripts on the current directory =./mytest.lua=, then in =./mytest/init.lua=, 
then for packages installed with luarocks and finally on official built-in sysbench dirs. 

#+hugo: more

Picture this, you are feeling a bit down, so you go to the doctor. The doctor sticks a termometer in your mouth, and after a few moments declares: you have a temperature of 98.6 degrees.

Is that high or low? - you ask.

The doctor replies: No idea.

Should you change doctors? Probably. The take is silly history is that if don't have a reference of what is the "normal" or baseline of, we are like the doctor: can't tell if we have a fever or not.

Too frequently we know we have a fever on when our users complain, that's not good.

That's why we need from time to time capture performance metrics, specially before and after there is some change (either software or hardware). 

There are lots alternatives to go around, but I'd like to talk today about Sysbench, in particular about benchmarking databases.


So, it seems to I only need to ensure the server has been running for some time before using the view. So easy! I should've known, things are never easy.

So I naively started to use this view to delete indexes. My workflow was something like this:

select * from sys.schema_unused_indexes where object_schema = 'my_overindexed_db';

Choose some 2 or 3 likely indexes to delete. 

Delete them. 

Run the view again

Repeat

At first I was being cautious, deleting indexes that where obviously not being used by anyone. But after some time I got somewhat excited and trigger happy, after all, the server was telling me that now one has used this indexes, so it's safe, right?

To make a long story short, the next day the application team reports slow performance. Strange, I say. I delve into the slow procedures and to my horror I find, that some of the indexes I deleted the day before where indeed needed and being used. What happened? Did the internet lie? How can this be?

Luckyly I keep all my DDL code in a git (LINK). So I was able very quickly to re-create the indexes, the tables were not too big so it didn't take too long.

Crisis averted, now I started wondering what has happened.

So I set up a minilab on my test environment (MySQL 5.7.22 Community)

CREATE SCHEMA indexes;

I create a new innodb table:

CREATE TABLE indexes.whats_the_deal (
	myid int not null auto_increment,
	name varchar(45) not null,
	birthday datetime not null,
	weight smallint null,
	PRIMARY KEY(myid),
	INDEX idx_name (name),
	INDEX idx_birthday (birthday)
);

USE indexes;

INSERT INTO whats_the_deal (name,birthday) VALUES ("Hayley","2018-05-06 12:52:23");
INSERT INTO whats_the_deal (name,birthday) VALUES ("Ciaran","2018-08-27 10:17:49");
INSERT INTO whats_the_deal (name,birthday) VALUES ("Lacey","2019-07-22 22:53:58");
INSERT INTO whats_the_deal (name,birthday) VALUES ("Dai","2018-12-14 17:59:06");
INSERT INTO whats_the_deal (name,birthday) VALUES ("Carson","2019-02-05 14:12:15");



I check the indexes, all are unused.
select * from sys.schema_unused_indexes where object_schema = 'indexes'

object_schema |object_name    |index_name   
--------------|---------------|-------------
indexes       |whats_the_deal |idx_name     
indexes       |whats_the_deal |idx_birthday 

No surprises there, after all this is a new table. Let's try a query that uses idx_birthday

select distinct birthday from indexes.whats_the_deal;

Check again the indexes: idx_birthday is no longer listed as unused. Good.

object_schema |object_name    |index_name 
--------------|---------------|-----------
indexes       |whats_the_deal |idx_name   

Let's try adding a new index to the table

ALTER TABLE indexes.whats_the_deal ADD INDEX idx_weight (weight)

What does the view say now?

select * from sys.schema_unused_indexes where object_schema = 'indexes'

object_schema |object_name    |index_name   
--------------|---------------|-------------
indexes       |whats_the_deal |idx_name     
indexes       |whats_the_deal |idx_birthday 
indexes       |whats_the_deal |idx_weight   

As I suspected, the unused index view has been 'reset'. The counters on the underling table are set to 0 after adding the index. And all indexes are listed as unused again. Seems to me there should be something about this on the documents.

So there you have it. Next time, before messing with the indexes, I'll check the create_time for the relevant table with something like SHOW TABLE STATUS

(EXAMPLE UNUSED INDEX QUERY)

Cheers


* *FAILED*
* Custom tests with sysbench           :mysql:pgsql:sysbench:guides:

This post is part 2 of my sysbench guide. If you haven't already please check part 1 where I cover the basics. 
In this post we'll see a more in depth analysis and a starter guide of writing our own tests.

** Other options

--rate=0
--skip_trx=off

What about the 20K "other" statements? What are those?

By default, the previous 14 statements are executed inside an explicit transaction, so we have 2 additional statements per event: "start transaction" and "commit"
-- The last 4 SELECTs (the ranges) can be disabled with --range-selects=off (default is on)

The number of each kind of SELECTs per event can be tweaked, as well as the range size, the options with their defaults:

--point_selects=10
--range_size=100
--simple_ranges=1
--sum_ranges=1
--order_ranges=1
--distinct_ranges=1


Each kind can be tweaked with its option:

--index_updates=1
--non_index_updates=1
--delete_inserts=1

With the defaults the total number writes are:

INSERTs = Events 
DELETEs = Events
UPDATEs = Events * 2
Total written rows = 4 * Events
*COMMON?* We can choose to run each statements separately in each own transaction with --skip_trx=on (a la AUTOCOMMIT). By default all the SELECTs will be executed in one explicit transaction.


Custom tests

** Where are the test scripts?
Sysbench uses lua as the scripting language. It's a simple straightforward language that has a very low system footprint.
Sysbench will look for script files first on the current directory, then it will look in the distribution's share
folder (=/usr/share/sysbench= but the location may be slightly different in your system). Go ahead and look for the files, I'll wait. 
You can open any of the lua files and take a peek.

sysbench MYTEST

./MYTEST.lua
./MYTEST/init.lua
./src/lua/MYTEST.lua
$HOME/.luarocks/share/lua
/usr/local/share/lua
/usr/share/sysbench
/usr/local/lib/lua
/usr/lib/sysbench

** Writing custom tests
Now we have an initial understanding on how the tool works, we can go ahead and create our own test scripts.

Sysbench uses lua as the scripting language. Don't worry if you are not fluent in lua, it's a really tidy and straightforward language.

The basic test code is

#+BEGIN_SRC lua 
function prepare_statement()
    ... prepare code ...
end

function event() 
    ... event code ...
end
#+END_SRC

Simple right? The

** Conclusion

* *TEST*
* English                                                       :org:testing:
:PROPERTIES:
:EXPORT_FILE_NAME: my-post
:END:

A post created with ox-hugo in org-mode

** Formatting 

*bold* /italics/ =monospace= ~keybind~ +strike-throuht+ _underline_


#+begin_src emacs-lisp -n
;; this will export with line number 1 (default)
(message "This is line 2")
#+end_src

#+attr_html: :class sane-table
| h1  | h2  | h3  |
|-----+-----+-----|
| abc | def | ghi |

> Quoted Text

Summary Splitter
#+hugo: more

Links
   [ [URL][CAPTION]]

Images
   INLINE [ [/images/filename.png]]

* Portugus                                           :org:testing:portugus:
:PROPERTIES:
:EXPORT_FILE_NAME: my-post.pt.md
:END:

A prova em portugus


#+BEGIN_SRC 
sadf [options] [ <interval> [ <count> ] ] [ <datafile> | -[0-9]+ ] -- [sar options]
#+END_SRC

sadf options

-p table 
-d CSV 
-r raw CSV (as read from the kernel)
-x XML
-d JSON 
-g SVG 

The options to the right of the *--* are sent to sar. This can be used to filter whar we want to see.

To select the file to read we can use either ~0~, ~-1~, etc to access daily activity files (as in automatic mode) or just 
provide the path to the datafile.

#+caption: yesterday's I/O activity in CSV format
#+BEGIN_SRC 
sadf -d -1  -- -b
# hostname;interval;timestamp;tps;rtps;wtps;bread/s;bwrtn/s
ix;1;2018-12-26 17:58:06 UTC;20.00;0.00;20.00;0.00;168.00
ix;1;2018-12-26 17:58:07 UTC;0.00;0.00;0.00;0.00;0.00
ix;1;2018-12-26 17:58:08 UTC;0.00;0.00;0.00;0.00;0.00
ix;1;2018-12-26 17:58:09 UTC;71.00;0.00;71.00;0.00;624.00
...
#+END_SRC

#+caption: CPU activity from my_metrics file in JSON format
#+BEGIN_SRC 
sadf -j my_metrics -- -u
{"sysstat": {
        "hosts": [
                {
                        "nodename": "ix",
                        "sysname": "Linux",
                        "release": "4.19.8-arch1-1-ARCH",
                        "machine": "x86_64",
                        "number-of-cpus": 4,
                        "file-date": "2018-12-26",
                        "file-utc-time": "17:58:05",
                        "statistics": [
                                {
                                        "timestamp": {"date": "2018-12-26", "time": "17:58:06", "utc": 1, "interval": 1},
                                        "cpu-load": [
                                                {"cpu": "all", "user": 16.11, "nice": 0.00, "system": 10.58, "iowait": 0.00, "steal": 0.00, "idle": 73.32}
                                        ]
                                },
...
#+END_SRC

With ~-g~ we get SVG format output which we can redirect to a file and see with an image viewer.

#+caption: Generate a CPU activity plot
#+BEGIN_SRC 
sadf -g -- -u > cpu.svg
#+END_SRC

#+caption: an example CPU utilization graph
[sadf-cpu-example.png]

#+caption: network device eth0 utilization plot
#+BEGIN_SRC 
sadf -g  -- -n DEV --iface=eth0 > a.svg
#+END_SRC

** Conclusion

Sharp readers may have noticed than really I only shown the utilities in the systat package [LINK]. It's true.



* Recycle?
** NOTAS METRIC
cpu+mem: vmstat -w -n -t 1 | tail -n +3
disk: vmstat -w -d -t 1


CPU
vmstat 1
vmstat reports information about processes, memory, paging, block IO, traps, disks
       and cpu activity

FIELD DESCRIPTION FOR VM MODE
   Procs
       r: The number of runnable processes (running or waiting for run time).
       b: The number of processes in uninterruptible sleep.

   Memory
       swpd: the amount of virtual memory used.
       free: the amount of idle memory.
       buff: the amount of memory used as buffers.
       cache: the amount of memory used as cache.
       inact: the amount of inactive memory.  (-a option)
       active: the amount of active memory.  (-a option)

   Swap
       si: Amount of memory swapped in from disk (/s).
       so: Amount of memory swapped to disk (/s).

   IO
       bi: Blocks received from a block device (blocks/s).
       bo: Blocks sent to a block device (blocks/s).

   System
       in: The number of interrupts per second, including the clock.
       cs: The number of context switches per second.

   CPU
       These are percentages of total CPU time.
       us: Time spent running non-kernel code.  (user time, including nice time)
       sy: Time spent running kernel code.  (system time)
       id: Time spent idle.  Prior to Linux 2.5.41, this includes IO-wait time.
       wa: Time spent waiting for IO.  Prior to Linux 2.5.41, included in idle.
       st: Time stolen from a virtual machine.  Prior to Linux 2.6.11, unknown.

FIELD DESCRIPTION FOR DISK MODE
   Reads
       total: Total reads completed successfully
       merged: grouped reads (resulting in one I/O)
       sectors: Sectors read successfully
       ms: milliseconds spent reading

   Writes
       total: Total writes completed successfully
       merged: grouped writes (resulting in one I/O)
       sectors: Sectors written successfully
       ms: milliseconds spent writing

   IO
       cur: I/O in progress
       s: seconds spent for I/O

FIELD DESCRIPTION FOR SLAB MODE
       cache: Cache name
       num: Number of currently active objects
       total: Total number of available objects
       size: Size of each object
       pages: Number of pages with at least one active object

** PREP
*** vmstat
http://blog.scoutapp.com/articles/2013/07/25/understanding-cpu-steal-time-when-should-you-be-worried
st: steal time VM, also in top, check on a virtual/cloud environment
Steal time is the percentage of time a virtual CPU waits for a real CPU while the hypervisor is servicing another virtual processor.
id: idle
wa: I/O wait

sysstat= iostat+mpstat+sar

sar -u 1

sar [-o repo] interval count 

sar [-f repo] [switches] interval count

network -n DEV --iface=wlp4s0
power management -m 
mounted -F
block devices -d
paging -B
i/o rates -b
memory utilization -r
swap utilization -S
cpu utilization -u
inode status -v
swapping -W
task creation -w
tty activity -y

- sar -P ALLwlp4s0
- dstat -c 
- mpstat -P ALL
- top/htop

MEM

vmstat -s
free
cat /proc/meminfo

slab
  vmstat -s 
  slabtop -s -c

DISK
vmstat -d 1

- free
- vmstat
- dstat -m,"free"
- sar -r,"%memused%"

 
- iotop
- iostat
- perf?

DB
- innotop?

* TODO Container comparison   :containers:docker:mariadb:benchmarks:sysbench:

[container-comp-1.png]
[container-comp-10.png]

LXC:
https://jlk.fjfi.cvut.cz/arch/manpages/man/lxc.container.conf.5

* TODO The cost of indexing on MySQL                       :mysql:benchmarks:
:PROPERTIES:
:EXPORT_FILE_NAME: cost-of-indexes
:END:

Recently I've been tidying up some MySQL indexes. This entails removing duplicates and redudant, and changing the keys when needed.

I got curious about how much of a performance bump we get by removing unused indexes, so I decided to run some benchmarks.

#+hugo: more

Indexes need to be updated when the referenced row changes, (are they synchronous?). So it is expected to have a penalized writes.

All tests are done on MySQL 5.7.28 and sysbench 1.0.15. 

*OLTP Insert*

I started with sysbench's default test table, which starts with 2 indexes, the primary key and an additional index: 

CREATE TABLE `sbtest1` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `k` int(11) NOT NULL DEFAULT '0',
  `c` char(120) NOT NULL DEFAULT '',
  `pad` char(60) NOT NULL DEFAULT '',
  PRIMARY KEY (`id`),
  KEY `k_1` (`k`)
)

I ran the sysbench oltp_insert test several turns, each time I added a some duplicate KEY(k) index. 
The tests were tuned more heavily on the write side, with a rate of 10 writes (updates,inserts,deletes) per each read.

[[/images/cost-of-indexes/oltp_insert.svg]]

We can see there is a almost linear relation between number of indexes and test time. The tests with 59 indexes took 2.6 times longer than with 4 indexes. That's a quite a lot.

*Bulk insert*

This test is completely focused on writes, so here we should see the most performance impact.

This is the time it took to insert 1M rows into an emptied table.

*OLTP delete*
*OLTP read only*
*OLTP read+write*
*OLTP write only*


* *NEXT*
* Welcome!
* *FAILED*
* Recycle Bin

# Would you buy a car or a bike without giving it a test drive? I sure wouldn't. 
# Unfortunately we can't always check what's under the hood before buying hardware, provisioning a VPS or a cloud machine.
# But we can benchmark it, find its capabilities, and hopefully check that is fits our needs.
# :: Is my server fast? How fast is fast? The answers are, of course, relative. 
# If you are planning in writing your own tests or downloading some you'll probably also want to install [[https://luarocks.org/][luarocks]] for additional lua packages. There is a also
# *If both --time and --events are 0, some tests may run forever*
# ** Why bother?
# ** Extending sysbench

With a little bit knowledge of Lua [LINK], we can write our own test. In addition you can download lua modules and additional sysbench tests. 

For downloading additional modules it's recommended to install =luarocks= which handles lua packages. There is an specialized luarocks repository for sysbench [LINK]

By default sybench will first check for the test scripts on the current directory =./mytest.lua=, then in =./mytest/init.lua=, 
then for packages installed with luarocks and finally on official built-in sysbench dirs. 

#+hugo: more

Picture this, you are feeling a bit down, so you go to the doctor. The doctor sticks a termometer in your mouth, and after a few moments declares: you have a temperature of 98.6 degrees.

Is that high or low? - you ask.

The doctor replies: No idea.

Should you change doctors? Probably. The take is silly history is that if don't have a reference of what is the "normal" or baseline of, we are like the doctor: can't tell if we have a fever or not.

Too frequently we know we have a fever on when our users complain, that's not good.

That's why we need from time to time capture performance metrics, specially before and after there is some change (either software or hardware). 

There are lots alternatives to go around, but I'd like to talk today about Sysbench, in particular about benchmarking databases.


So, it seems to I only need to ensure the server has been running for some time before using the view. So easy! I should've known, things are never easy.

So I naively started to use this view to delete indexes. My workflow was something like this:

select * from sys.schema_unused_indexes where object_schema = 'my_overindexed_db';

Choose some 2 or 3 likely indexes to delete. 

Delete them. 

Run the view again

Repeat

At first I was being cautious, deleting indexes that where obviously not being used by anyone. But after some time I got somewhat excited and trigger happy, after all, the server was telling me that now one has used this indexes, so it's safe, right?

To make a long story short, the next day the application team reports slow performance. Strange, I say. I delve into the slow procedures and to my horror I find, that some of the indexes I deleted the day before where indeed needed and being used. What happened? Did the internet lie? How can this be?

Luckyly I keep all my DDL code in a git (LINK). So I was able very quickly to re-create the indexes, the tables were not too big so it didn't take too long.

Crisis averted, now I started wondering what has happened.

So I set up a minilab on my test environment (MySQL 5.7.22 Community)

CREATE SCHEMA indexes;

I create a new innodb table:

CREATE TABLE indexes.whats_the_deal (
	myid int not null auto_increment,
	name varchar(45) not null,
	birthday datetime not null,
	weight smallint null,
	PRIMARY KEY(myid),
	INDEX idx_name (name),
	INDEX idx_birthday (birthday)
);

USE indexes;

INSERT INTO whats_the_deal (name,birthday) VALUES ("Hayley","2018-05-06 12:52:23");
INSERT INTO whats_the_deal (name,birthday) VALUES ("Ciaran","2018-08-27 10:17:49");
INSERT INTO whats_the_deal (name,birthday) VALUES ("Lacey","2019-07-22 22:53:58");
INSERT INTO whats_the_deal (name,birthday) VALUES ("Dai","2018-12-14 17:59:06");
INSERT INTO whats_the_deal (name,birthday) VALUES ("Carson","2019-02-05 14:12:15");



I check the indexes, all are unused.
select * from sys.schema_unused_indexes where object_schema = 'indexes'

object_schema |object_name    |index_name   
--------------|---------------|-------------
indexes       |whats_the_deal |idx_name     
indexes       |whats_the_deal |idx_birthday 

No surprises there, after all this is a new table. Let's try a query that uses idx_birthday

select distinct birthday from indexes.whats_the_deal;

Check again the indexes: idx_birthday is no longer listed as unused. Good.

object_schema |object_name    |index_name 
--------------|---------------|-----------
indexes       |whats_the_deal |idx_name   

Let's try adding a new index to the table

ALTER TABLE indexes.whats_the_deal ADD INDEX idx_weight (weight)

What does the view say now?

select * from sys.schema_unused_indexes where object_schema = 'indexes'

object_schema |object_name    |index_name   
--------------|---------------|-------------
indexes       |whats_the_deal |idx_name     
indexes       |whats_the_deal |idx_birthday 
indexes       |whats_the_deal |idx_weight   

As I suspected, the unused index view has been 'reset'. The counters on the underling table are set to 0 after adding the index. And all indexes are listed as unused again. Seems to me there should be something about this on the documents.

So there you have it. Next time, before messing with the indexes, I'll check the create_time for the relevant table with something like SHOW TABLE STATUS

(EXAMPLE UNUSED INDEX QUERY)

Cheers

* Custom tests with sysbench           :mysql:pgsql:sysbench:guides:

This post is part 2 of my sysbench guide. If you haven't already please check part 1 where I cover the basics. 
In this post we'll see a more in depth analysis and a starter guide of writing our own tests.

** Other options

--rate=0
--skip_trx=off

What about the 20K "other" statements? What are those?

By default, the previous 14 statements are executed inside an explicit transaction, so we have 2 additional statements per event: "start transaction" and "commit"
-- The last 4 SELECTs (the ranges) can be disabled with --range-selects=off (default is on)

The number of each kind of SELECTs per event can be tweaked, as well as the range size, the options with their defaults:

--point_selects=10
--range_size=100
--simple_ranges=1
--sum_ranges=1
--order_ranges=1
--distinct_ranges=1


Each kind can be tweaked with its option:

--index_updates=1
--non_index_updates=1
--delete_inserts=1

With the defaults the total number writes are:

INSERTs = Events 
DELETEs = Events
UPDATEs = Events * 2
Total written rows = 4 * Events
*COMMON?* We can choose to run each statements separately in each own transaction with --skip_trx=on (a la AUTOCOMMIT). By default all the SELECTs will be executed in one explicit transaction.


Custom tests

** Where are the test scripts?
Sysbench uses lua as the scripting language. It's a simple straightforward language that has a very low system footprint.
Sysbench will look for script files first on the current directory, then it will look in the distribution's share
folder (=/usr/share/sysbench= but the location may be slightly different in your system). Go ahead and look for the files, I'll wait. 
You can open any of the lua files and take a peek.

sysbench MYTEST

./MYTEST.lua
./MYTEST/init.lua
./src/lua/MYTEST.lua
$HOME/.luarocks/share/lua
/usr/local/share/lua
/usr/share/sysbench
/usr/local/lib/lua
/usr/lib/sysbench

** Writing custom tests
Now we have an initial understanding on how the tool works, we can go ahead and create our own test scripts.

Sysbench uses lua as the scripting language. Don't worry if you are not fluent in lua, it's a really tidy and straightforward language.

The basic test code is

#+BEGIN_SRC lua 
function prepare_statement()
    ... prepare code ...
end

function event() 
    ... event code ...
end
#+END_SRC

Simple right? The

** Conclusion

* *IDEAS*
* Optimizing docker performance (for dbs) (title in progress)
* Benchmarking mysql vs maria vs percona
* Benchmarking innodb, file format, row format, myisam
* Benchmarking tokudb, rocksdb, xtradb
* Benchmarking Fs types, ext4, ext3, ext2, xfs, zfs

* *TEST*
* English                                                       :org:testing:
:PROPERTIES:
:EXPORT_FILE_NAME: my-post
:END:

A post created with ox-hugo in org-mode

** Formatting 

*bold* /italics/ =monospace= ~keybind~ +strike-throuht+ _underline_


#+begin_src emacs-lisp -n
;; this will export with line number 1 (default)
(message "This is line 2")
#+end_src

#+attr_html: :class sane-table
| h1  | h2  | h3  |
|-----+-----+-----|
| abc | def | ghi |

> Quoted Text

Summary Splitter
#+hugo: more

Links
   [ [URL][CAPTION]]

Images
   INLINE [ [/images/filename.png]]

* Portugus                                           :org:testing:portugus:
:PROPERTIES:
:EXPORT_FILE_NAME: my-post.pt.md
:END:

A prova em portugus

